# 96
telegram:
#  net: QiGi3
  layer: 4
  lr: 0.01
  BN_model: True    # sure
  First_self_loop: True
  jk: 'max'
  dropout: 0.0


# 96
WikipediaNetwork/chameleon:
  dropout: 0.0  # 0.5(acc65), 0.0(acc75)
  net:
  layer:
  lr:
  BN_model: 1 # without layerNorm, very bad
  self_loop: "remove"
  jk: 'max'

WikipediaNetwork/squirrel:
  dropout: 0.0  # 0.5(acc72.7), 0.0(acc75)
  net:
  layer: 4
  lr:
  BN_model: 1 # 0(48.9), 1(72)
  self_loop: "remove"     # Sure
  jk: 'max'



#
cora_ml:
#  net: QiGi3
  layer: 2   # 2(80), 3(75), 4(79.8), 5(79.6)
  lr: 0.01    # 0.1(79), 0.01(80.7)
  BN_model: 1   # 0(29), 1(79)
  First_self_loop : 'add'  # sure
  jk: "max"     # max(80.7), cat(79.8), 0(76.9)
#  dropout: 0.5   # 0.0(80.51), 0.5(80.76)

#
citeseer_npz:
  layer: 2     # 1(65.3),2(64.8), 3(62.6), 4(64.0), 5(64.4)
  lr: 0.01
  BN_model: 1   # 0(62.63), 1(64.75)
  First_self_loop : 'add'     # 'add'(64.75), 'remove'(58.2), 0(57.5)
  jk: 'cat'   # 'max'(64.75). 'cat'(65.6), 0(55.1)
  dropout: 0.5   # 0(61.44), 0.5(64.75)
  inci_norm: 'dir'    # dir(64.8), sym(63.9), row(63.8)


#
dgl/pubmed:
  net:
  layer: 4
  lr:
  BN_model: 1  # 0(33), 1(73)
  First_self_loop : True
  jk: 'max'
  dropout: 0.0  #0.5(39), 0.0(77.5)

#
WikiCS/:
  net:
  layer: 2
  lr:
  BN_model: 1  # 0(23), 1(73.5)
  self_loop : 'remove'  # remove(73.9), add(73.7), 0(73.85)
  jk: 'max'   # max(75.9),cat(75.99), 0(73.5)
  dropout: 0.5  # 0.5(75.9), 0.0(73.9)