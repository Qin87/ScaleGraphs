# 96
telegram/:
  net: ScaleNet         # QiGi3
  layer: 4
  lr: 0.01
  BN_model: 1    # sure
  First_self_loop: 'add'
  jk: 'max'
  dropout: 0.0
  alphaDir: 0.5
  betaDir: -1
  gamaDir: -1



# 96
WikipediaNetwork/chameleon:
  dropout: 0.0  # 0.5(acc65), 0.0(acc75)
  net: ScaleNet
  layer: 2
  lr: 0.01
  BN_model: 1 # without layerNorm, very bad
  self_loop: "remove"
  jk: 'max'
  alphaDir: 1
  betaDir: 1
  gamaDir: 1

WikipediaNetwork/squirrel:
  dropout: 0.0  # 0.5(acc72.7), 0.0(acc75)
  net:
  layer: 4
  lr:
  BN_model: 1 # 0(48.9), 1(72)
  self_loop: "remove"     # Sure
  jk: 'max'
  alphaDir:
  betaDir:
  gamaDir:




#
cora_ml/:
#  net: ScaleNet   #  net: QiGi3

  layer: 2   # 2(80), 3(75), 4(79.8), 5(79.6)
  lr: 0.01    # 0.1(79), 0.01(80.7)
  BN_model: 1   # 0(29), 1(79)
  First_self_loop : 'add'  # sure
  jk: "max"     # max(80.7), cat(79.8), 0(76.9)
  dropout: 0.5   # 0.0(80.51), 0.5(80.76)
  alphaDir: 0.5
  betaDir: 1  # 1
  gamaDir: -1  # -1 , 0.5

#
citeseer_npz/:
#  net: ScaleNet
  layer: 2     # 1(65.3),2(64.8), 3(62.6), 4(64.0), 5(64.4)
  lr: 0.01
  BN_model: 1   # 0(62.63), 1(64.75)
  First_self_loop : 'add'     # 'add'(64.75), 'remove'(58.2), 0(57.5)
  jk: 'cat'   # 'max'(64.75). 'cat'(65.6), 0(55.1)
  dropout: 0.5   # 0(61.44), 0.5(64.75)
  inci_norm: 'dir'    # dir(64.8), sym(63.9), row(63.8)
  alphaDir: -1
  betaDir: 0
  gamaDir: -1


#
dgl/pubmed:
#  net: ScaleNet
  layer: 4
  lr: 0.01
  BN_model: 1  # 0(33), 1(73)
  First_self_loop : 'add'
  jk: 'max'
  dropout: 0.0  #0.5(39), 0.0(77.5)
  alphaDir: 0   #
  betaDir: 0.5
  gamaDir: 1

#
WikiCS/:
#  net: ScaleNet
  layer: 2
  lr: 0.01
  BN_model: 1  # 0(23), 1(73.5)
  First_self_loop : 'remove'  # remove(73.9), add(73.7), 0(73.85)
  jk: 'max'   # max(75.9),cat(75.99), 0(73.5)
  dropout: 0.5  # 0.5(75.9), 0.0(73.9)
  alphaDir: -1
  betaDir: 0.5
  gamaDir: -1   #0  -1